{"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_22":{"weighted_accuracy":[0.9540787594368496],"accuracy":[0.9529411764705884],"precision_score_micro":[0.9529411764705884],"norm_macro_recall":[0.9022222222222223],"precision_score_macro":[0.9573785936285937],"f1_score_micro":[0.9529411764705884],"average_precision_score_macro":[0.9952553310886645],"log_loss":[0.29889844694038553],"AUC_macro":[0.9944444444444445],"average_precision_score_micro":[0.9926045614324162],"balanced_accuracy":[0.9511111111111111],"precision_score_weighted":[0.9597751268339504],"AUC_micro":[0.9916955017301037],"f1_score_weighted":[0.9524587318874571],"recall_score_weighted":[0.9529411764705884],"recall_score_micro":[0.9529411764705884],"recall_score_macro":[0.9511111111111111],"average_precision_score_weighted":[0.995258467023173],"f1_score_macro":[0.950059872177149],"AUC_weighted":[0.9944444444444445],"matthews_correlation":[0.9080956702499069]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_4":{"AUC_weighted":[0.9986111111111111],"norm_macro_recall":[0.9369444444444444],"log_loss":[0.14099732417688277],"average_precision_score_weighted":[0.9987581699346405],"recall_score_weighted":[0.9705882352941178],"precision_score_macro":[0.9704594017094017],"f1_score_weighted":[0.970518587408613],"weighted_accuracy":[0.9720097939196082],"balanced_accuracy":[0.9684722222222222],"average_precision_score_micro":[0.996477594649831],"recall_score_macro":[0.9684722222222222],"AUC_macro":[0.9986111111111111],"AUC_micro":[0.9961937716262976],"accuracy":[0.9705882352941178],"matthews_correlation":[0.9386123000100224],"recall_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"precision_score_weighted":[0.9726747109100049],"average_precision_score_macro":[0.99875],"f1_score_macro":[0.9680371683587795],"precision_score_micro":[0.9705882352941178]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_26":{"weighted_accuracy":[0.9775270352989185],"average_precision_score_weighted":[0.997325289089995],"matthews_correlation":[0.9511123000100223],"f1_score_micro":[0.9764705882352942],"log_loss":[0.07835484484355444],"f1_score_macro":[0.9739603709731586],"AUC_macro":[0.9969444444444445],"AUC_weighted":[0.9969444444444445],"recall_score_weighted":[0.9764705882352942],"f1_score_weighted":[0.9764009403497894],"average_precision_score_micro":[0.9974159736133874],"norm_macro_recall":[0.9494444444444443],"recall_score_macro":[0.9747222222222222],"balanced_accuracy":[0.9747222222222222],"precision_score_weighted":[0.9792106586224232],"precision_score_micro":[0.9764705882352942],"average_precision_score_macro":[0.9967628205128205],"recall_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"AUC_micro":[0.9972318339100346],"accuracy":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_33":{"log_loss":[0.16687098498146732],"f1_score_weighted":[0.970518587408613],"recall_score_macro":[0.9684722222222222],"average_precision_score_macro":[0.9975000000000002],"balanced_accuracy":[0.9684722222222222],"precision_score_weighted":[0.9726747109100049],"AUC_micro":[0.9955017301038062],"precision_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"AUC_macro":[0.9972222222222221],"weighted_accuracy":[0.9720097939196082],"norm_macro_recall":[0.9369444444444444],"recall_score_weighted":[0.9705882352941178],"precision_score_macro":[0.9704594017094017],"matthews_correlation":[0.9386123000100224],"recall_score_micro":[0.9705882352941178],"accuracy":[0.9705882352941178],"average_precision_score_weighted":[0.997516339869281],"f1_score_macro":[0.9680371683587795],"average_precision_score_micro":[0.9958689688465686],"AUC_weighted":[0.9972222222222221]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_29":{"AUC_macro":[0.9986111111111111],"matthews_correlation":[0.9511123000100223],"average_precision_score_macro":[0.99875],"recall_score_weighted":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"weighted_accuracy":[0.9775270352989185],"f1_score_weighted":[0.9764009403497894],"precision_score_micro":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"AUC_micro":[0.9979238754325259],"precision_score_macro":[0.9767094017094017],"balanced_accuracy":[0.9747222222222222],"accuracy":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"f1_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9980543920354521],"log_loss":[0.17428125960766222],"average_precision_score_weighted":[0.9987581699346405],"AUC_weighted":[0.9986111111111111],"norm_macro_recall":[0.9494444444444443],"recall_score_micro":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_34":{"AUC_weighted":[1.0],"norm_macro_recall":[0.9494444444444443],"precision_score_macro":[0.9767094017094017],"precision_score_weighted":[0.9792106586224232],"average_precision_score_weighted":[1.0],"matthews_correlation":[0.9511123000100223],"recall_score_weighted":[0.9764705882352942],"log_loss":[0.05235003706819462],"AUC_macro":[1.0],"AUC_micro":[0.9986159169550172],"f1_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"recall_score_macro":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"accuracy":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"f1_score_weighted":[0.9764009403497894],"precision_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_28":{"recall_score_micro":[0.9705882352941178],"recall_score_macro":[0.9684722222222222],"average_precision_score_weighted":[0.997516339869281],"matthews_correlation":[0.9386123000100224],"recall_score_weighted":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"AUC_macro":[0.9972222222222221],"precision_score_weighted":[0.9726747109100049],"precision_score_micro":[0.9705882352941178],"log_loss":[0.13775454109486338],"accuracy":[0.9705882352941178],"balanced_accuracy":[0.9684722222222222],"weighted_accuracy":[0.9720097939196082],"precision_score_macro":[0.9704594017094017],"f1_score_weighted":[0.970518587408613],"average_precision_score_macro":[0.9975000000000002],"norm_macro_recall":[0.9369444444444444],"AUC_weighted":[0.9972222222222221],"AUC_micro":[0.9955017301038062],"average_precision_score_micro":[0.9958473425489908],"f1_score_macro":[0.9680371683587795]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_31":{"precision_score_micro":[0.9764705882352942],"norm_macro_recall":[0.9494444444444443],"accuracy":[0.9764705882352942],"average_precision_score_macro":[1.0],"matthews_correlation":[0.9511123000100223],"AUC_macro":[1.0],"average_precision_score_micro":[0.9986928104575163],"f1_score_weighted":[0.9764009403497894],"weighted_accuracy":[0.9775270352989185],"recall_score_macro":[0.9747222222222222],"log_loss":[0.05768108765235188],"AUC_weighted":[1.0],"balanced_accuracy":[0.9747222222222222],"recall_score_weighted":[0.9764705882352942],"average_precision_score_weighted":[1.0],"precision_score_weighted":[0.9792106586224232],"AUC_micro":[0.9986159169550172],"recall_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"precision_score_macro":[0.9767094017094017],"f1_score_micro":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_30":{"f1_score_macro":[0.29416757316757314],"recall_score_macro":[0.5],"precision_score_weighted":[0.18892733564013842],"AUC_macro":[0.5],"matthews_correlation":[0.0],"norm_macro_recall":[0.0],"log_loss":[0.7013061098925675],"f1_score_weighted":[0.2587236771942655],"average_precision_score_micro":[0.47716262975778545],"average_precision_score_weighted":[0.5307958477508651],"precision_score_macro":[0.21176470588235294],"precision_score_micro":[0.4235294117647059],"accuracy":[0.4235294117647059],"average_precision_score_macro":[0.5],"AUC_micro":[0.4235294117647059],"balanced_accuracy":[0.5],"recall_score_weighted":[0.4235294117647059],"weighted_accuracy":[0.36554046633408604],"AUC_weighted":[0.5],"f1_score_micro":[0.4235294117647059],"recall_score_micro":[0.4235294117647059]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_0":{"recall_score_macro":[0.9747222222222222],"log_loss":[0.09169236604145156],"f1_score_weighted":[0.9764009403497894],"balanced_accuracy":[0.9747222222222222],"average_precision_score_macro":[0.9967628205128205],"f1_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"accuracy":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"average_precision_score_weighted":[0.997325289089995],"AUC_weighted":[0.9969444444444445],"precision_score_weighted":[0.9792106586224232],"precision_score_macro":[0.9767094017094017],"recall_score_micro":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9961467502377627],"AUC_macro":[0.9969444444444445],"norm_macro_recall":[0.9494444444444443],"AUC_micro":[0.9958477508650517],"f1_score_macro":[0.9739603709731586],"weighted_accuracy":[0.9775270352989185]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_3":{"f1_score_micro":[0.9764705882352942],"precision_score_macro":[0.9743055555555555],"average_precision_score_macro":[0.99875],"average_precision_score_micro":[0.9974351969890124],"f1_score_weighted":[0.9766100906765869],"log_loss":[0.283771576708101],"recall_score_weighted":[0.9764705882352942],"recall_score_macro":[0.9784722222222223],"AUC_micro":[0.9972318339100348],"AUC_macro":[0.9986111111111111],"f1_score_macro":[0.9755927239143352],"precision_score_weighted":[0.9781045751633988],"accuracy":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"norm_macro_recall":[0.9569444444444445],"matthews_correlation":[0.9526785151252903],"average_precision_score_weighted":[0.9987581699346405],"balanced_accuracy":[0.9784722222222223],"recall_score_micro":[0.9764705882352942],"AUC_weighted":[0.9986111111111111],"weighted_accuracy":[0.9749683738012651]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_1":{"accuracy":[0.9705882352941178],"AUC_weighted":[0.9969444444444445],"norm_macro_recall":[0.9369444444444444],"recall_score_weighted":[0.9705882352941178],"AUC_micro":[0.9955017301038062],"f1_score_macro":[0.9680371683587795],"AUC_macro":[0.9969444444444445],"f1_score_weighted":[0.970518587408613],"average_precision_score_weighted":[0.997325289089995],"matthews_correlation":[0.9386123000100224],"precision_score_micro":[0.9705882352941178],"precision_score_weighted":[0.9726747109100049],"recall_score_macro":[0.9684722222222222],"log_loss":[0.06953465307505337],"f1_score_micro":[0.9705882352941178],"recall_score_micro":[0.9705882352941178],"average_precision_score_micro":[0.9958391762277665],"weighted_accuracy":[0.9720097939196082],"average_precision_score_macro":[0.9967628205128205],"precision_score_macro":[0.9704594017094017],"balanced_accuracy":[0.9684722222222222]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_5":{"f1_score_micro":[0.9647058823529413],"average_precision_score_micro":[0.9938654884038238],"precision_score_macro":[0.9684554334554335],"average_precision_score_macro":[0.9951781705948374],"recall_score_micro":[0.9647058823529413],"accuracy":[0.9647058823529413],"weighted_accuracy":[0.9666965925321364],"balanced_accuracy":[0.9615277777777779],"AUC_micro":[0.9930795847750865],"matthews_correlation":[0.9297577003309744],"AUC_macro":[0.9944444444444445],"precision_score_micro":[0.9647058823529413],"f1_score_weighted":[0.9643333333333335],"recall_score_macro":[0.9615277777777779],"f1_score_macro":[0.9629509803921568],"average_precision_score_weighted":[0.9951767676767677],"norm_macro_recall":[0.9230555555555556],"precision_score_weighted":[0.9676607053077643],"log_loss":[0.3625386927838666],"AUC_weighted":[0.9944444444444445],"recall_score_weighted":[0.9647058823529413]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_9":{"log_loss":[0.3024174996529746],"weighted_accuracy":[0.9587023056519077],"average_precision_score_macro":[0.9975000000000002],"AUC_macro":[0.9972222222222221],"f1_score_macro":[0.9553945981554678],"AUC_micro":[0.9941176470588236],"recall_score_weighted":[0.9588235294117646],"f1_score_weighted":[0.9588116846211475],"precision_score_micro":[0.9588235294117646],"average_precision_score_micro":[0.9946133788912883],"norm_macro_recall":[0.9175000000000001],"recall_score_micro":[0.9588235294117646],"precision_score_weighted":[0.9635897435897436],"balanced_accuracy":[0.95875],"recall_score_macro":[0.95875],"AUC_weighted":[0.9972222222222221],"matthews_correlation":[0.9160052122433078],"accuracy":[0.9588235294117646],"precision_score_macro":[0.9576816239316239],"average_precision_score_weighted":[0.997516339869281],"f1_score_micro":[0.9588235294117646]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_2":{"precision_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"AUC_weighted":[1.0],"AUC_micro":[0.9965397923875432],"balanced_accuracy":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"accuracy":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"recall_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"average_precision_score_micro":[0.9967851686598271],"f1_score_micro":[0.9764705882352942],"log_loss":[0.09175611125045713],"f1_score_weighted":[0.9764009403497894],"average_precision_score_weighted":[1.0],"AUC_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"norm_macro_recall":[0.9494444444444443],"average_precision_score_macro":[1.0],"recall_score_macro":[0.9747222222222222]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_6":{"accuracy":[0.9705882352941178],"recall_score_weighted":[0.9705882352941178],"matthews_correlation":[0.9386123000100224],"recall_score_macro":[0.9684722222222222],"norm_macro_recall":[0.9369444444444444],"AUC_weighted":[0.9969444444444445],"weighted_accuracy":[0.9720097939196082],"precision_score_micro":[0.9705882352941178],"f1_score_weighted":[0.970518587408613],"AUC_macro":[0.9969444444444445],"precision_score_macro":[0.9704594017094017],"average_precision_score_weighted":[0.997325289089995],"average_precision_score_macro":[0.9967628205128205],"precision_score_weighted":[0.9726747109100049],"recall_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"balanced_accuracy":[0.9684722222222222],"f1_score_macro":[0.9680371683587795],"average_precision_score_micro":[0.9971083996033914],"log_loss":[0.2590568021043464],"AUC_micro":[0.996885813148789]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_8":{"average_precision_score_macro":[0.9957380952380952],"AUC_weighted":[0.9966666666666667],"f1_score_macro":[0.9739603709731586],"average_precision_score_weighted":[0.9970028011204481],"norm_macro_recall":[0.9494444444444443],"precision_score_macro":[0.9767094017094017],"log_loss":[0.07554388735695901],"balanced_accuracy":[0.9747222222222222],"precision_score_weighted":[0.9792106586224232],"precision_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9967851686598271],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"f1_score_weighted":[0.9764009403497894],"recall_score_macro":[0.9747222222222222],"AUC_micro":[0.9965397923875431],"recall_score_micro":[0.9764705882352942],"AUC_macro":[0.9966666666666667],"accuracy":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_11":{"average_precision_score_micro":[0.9977468180254558],"log_loss":[0.27928275608402325],"precision_score_micro":[0.9705882352941178],"AUC_micro":[0.9975778546712804],"AUC_macro":[0.9986111111111111],"balanced_accuracy":[0.9684722222222222],"recall_score_weighted":[0.9705882352941178],"matthews_correlation":[0.9386123000100224],"average_precision_score_weighted":[0.9987581699346405],"accuracy":[0.9705882352941178],"weighted_accuracy":[0.9720097939196082],"average_precision_score_macro":[0.99875],"recall_score_macro":[0.9684722222222222],"f1_score_macro":[0.9680371683587795],"AUC_weighted":[0.9986111111111111],"precision_score_macro":[0.9704594017094017],"f1_score_weighted":[0.970518587408613],"norm_macro_recall":[0.9369444444444444],"precision_score_weighted":[0.9726747109100049],"recall_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_13":{"norm_macro_recall":[0.9494444444444443],"precision_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"matthews_correlation":[0.9511123000100223],"AUC_macro":[1.0],"recall_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"AUC_weighted":[1.0],"log_loss":[0.041665914208758204],"precision_score_weighted":[0.9792106586224232],"f1_score_macro":[0.9739603709731586],"AUC_micro":[0.9986159169550172],"recall_score_macro":[0.9747222222222222],"balanced_accuracy":[0.9747222222222222],"accuracy":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"average_precision_score_weighted":[1.0],"f1_score_weighted":[0.9764009403497894],"recall_score_weighted":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_7":{"balanced_accuracy":[0.9747222222222222],"recall_score_macro":[0.9747222222222222],"average_precision_score_weighted":[1.0],"precision_score_macro":[0.9767094017094017],"AUC_micro":[0.9986159169550172],"AUC_weighted":[1.0],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"norm_macro_recall":[0.9494444444444443],"AUC_macro":[1.0],"recall_score_weighted":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"average_precision_score_micro":[0.9986928104575163],"precision_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"f1_score_weighted":[0.9764009403497894],"accuracy":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"log_loss":[0.048804713895068776]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_10":{"recall_score_weighted":[0.9705882352941178],"recall_score_macro":[0.9684722222222222],"AUC_macro":[0.9986111111111111],"norm_macro_recall":[0.9369444444444444],"average_precision_score_weighted":[0.9987581699346405],"average_precision_score_micro":[0.9971083996033914],"weighted_accuracy":[0.9720097939196082],"f1_score_weighted":[0.970518587408613],"precision_score_weighted":[0.9726747109100049],"recall_score_micro":[0.9705882352941178],"matthews_correlation":[0.9386123000100224],"f1_score_micro":[0.9705882352941178],"AUC_micro":[0.996885813148789],"log_loss":[0.14233186299666456],"accuracy":[0.9705882352941178],"precision_score_macro":[0.9704594017094017],"AUC_weighted":[0.9986111111111111],"balanced_accuracy":[0.9684722222222222],"precision_score_micro":[0.9705882352941178],"average_precision_score_macro":[0.99875],"f1_score_macro":[0.9680371683587795]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_15":{"weighted_accuracy":[0.9775270352989185],"average_precision_score_micro":[0.9986928104575163],"accuracy":[0.9764705882352942],"average_precision_score_weighted":[1.0],"f1_score_macro":[0.9739603709731586],"AUC_weighted":[1.0],"average_precision_score_macro":[1.0],"recall_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"recall_score_weighted":[0.9764705882352942],"f1_score_weighted":[0.9764009403497894],"AUC_macro":[1.0],"log_loss":[0.07917089863413578],"matthews_correlation":[0.9511123000100223],"AUC_micro":[0.9986159169550172],"precision_score_macro":[0.9767094017094017],"f1_score_micro":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"precision_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"norm_macro_recall":[0.9494444444444443]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_16":{"f1_score_macro":[0.9739603709731586],"f1_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"log_loss":[0.061556207339617766],"weighted_accuracy":[0.9775270352989185],"precision_score_weighted":[0.9792106586224232],"accuracy":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"norm_macro_recall":[0.9494444444444443],"recall_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"AUC_macro":[1.0],"balanced_accuracy":[0.9747222222222222],"matthews_correlation":[0.9511123000100223],"AUC_weighted":[1.0],"f1_score_weighted":[0.9764009403497894],"average_precision_score_macro":[1.0],"recall_score_weighted":[0.9764705882352942],"AUC_micro":[0.9986159169550172],"recall_score_macro":[0.9747222222222222],"average_precision_score_weighted":[1.0]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_17":{"AUC_macro":[1.0],"balanced_accuracy":[0.9802777777777777],"recall_score_micro":[0.9823529411764707],"average_precision_score_micro":[0.9983811894210728],"precision_score_micro":[0.9823529411764707],"f1_score_macro":[0.979842723914335],"AUC_weighted":[1.0],"f1_score_weighted":[0.9822832932909659],"log_loss":[0.06422793451903017],"recall_score_weighted":[0.9823529411764707],"matthews_correlation":[0.9622234111211334],"f1_score_micro":[0.9823529411764707],"recall_score_macro":[0.9802777777777777],"average_precision_score_macro":[1.0],"precision_score_macro":[0.9822649572649572],"average_precision_score_weighted":[1.0],"norm_macro_recall":[0.9605555555555554],"precision_score_weighted":[0.9844394167923578],"AUC_micro":[0.9982698961937716],"accuracy":[0.9823529411764707],"weighted_accuracy":[0.9837339318506426]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_12":{"precision_score_weighted":[0.9792106586224232],"norm_macro_recall":[0.9494444444444443],"average_precision_score_weighted":[1.0],"recall_score_macro":[0.9747222222222222],"log_loss":[0.08276036113345764],"weighted_accuracy":[0.9775270352989185],"recall_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"matthews_correlation":[0.9511123000100223],"AUC_weighted":[1.0],"f1_score_weighted":[0.9764009403497894],"accuracy":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"precision_score_macro":[0.9767094017094017],"AUC_micro":[0.9986159169550172],"recall_score_weighted":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"average_precision_score_macro":[1.0],"AUC_macro":[1.0],"precision_score_micro":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_20":{"f1_score_macro":[0.9377039824528384],"balanced_accuracy":[0.9412500000000001],"precision_score_micro":[0.9411764705882353],"average_precision_score_macro":[1.0],"AUC_macro":[1.0],"f1_score_micro":[0.9411764705882353],"precision_score_macro":[0.9499038461538463],"f1_score_weighted":[0.9400167199949809],"norm_macro_recall":[0.8825],"AUC_weighted":[1.0],"accuracy":[0.9411764705882353],"matthews_correlation":[0.8905560414449131],"average_precision_score_micro":[0.9888092311227897],"AUC_micro":[0.9875432525951556],"precision_score_weighted":[0.9541289592760182],"log_loss":[0.17722799562508118],"recall_score_weighted":[0.9411764705882353],"recall_score_micro":[0.9411764705882353],"average_precision_score_weighted":[1.0],"weighted_accuracy":[0.9404707983167384],"recall_score_macro":[0.9412500000000001]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_27":{"AUC_micro":[0.9986159169550172],"f1_score_macro":[0.9739603709731586],"log_loss":[0.04203177437498601],"precision_score_micro":[0.9764705882352942],"AUC_macro":[1.0],"matthews_correlation":[0.9511123000100223],"recall_score_macro":[0.9747222222222222],"average_precision_score_weighted":[1.0],"f1_score_micro":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"f1_score_weighted":[0.9764009403497894],"norm_macro_recall":[0.9494444444444443],"precision_score_weighted":[0.9792106586224232],"weighted_accuracy":[0.9775270352989185],"AUC_weighted":[1.0],"average_precision_score_macro":[1.0],"average_precision_score_micro":[0.9986928104575163],"balanced_accuracy":[0.9747222222222222],"accuracy":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_24":{"average_precision_score_macro":[0.981972746003996],"precision_score_weighted":[0.9792106586224232],"recall_score_weighted":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"AUC_weighted":[0.9827777777777778],"f1_score_macro":[0.9739603709731586],"balanced_accuracy":[0.9747222222222222],"weighted_accuracy":[0.9775270352989185],"norm_macro_recall":[0.9494444444444443],"AUC_micro":[0.9882352941176469],"recall_score_macro":[0.9747222222222222],"AUC_macro":[0.9827777777777778],"f1_score_weighted":[0.9764009403497894],"accuracy":[0.9764705882352942],"log_loss":[0.1118750099982457],"recall_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"average_precision_score_weighted":[0.985496447996448],"average_precision_score_micro":[0.9890616305071323],"matthews_correlation":[0.9511123000100223]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_37":{"average_precision_score_macro":[1.0],"precision_score_macro":[0.9767094017094017],"AUC_macro":[1.0],"matthews_correlation":[0.9511123000100223],"log_loss":[0.07056990675312638],"AUC_weighted":[1.0],"precision_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"precision_score_weighted":[0.9792106586224232],"weighted_accuracy":[0.9775270352989185],"f1_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9980543920354519],"f1_score_weighted":[0.9764009403497894],"recall_score_macro":[0.9747222222222222],"norm_macro_recall":[0.9494444444444443],"average_precision_score_weighted":[1.0],"AUC_micro":[0.9979238754325259],"accuracy":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_14":{"recall_score_weighted":[0.9470588235294117],"AUC_micro":[0.9913494809688583],"AUC_weighted":[0.9944444444444445],"accuracy":[0.9470588235294117],"log_loss":[0.32475337134579546],"f1_score_weighted":[0.9467844972813341],"precision_score_micro":[0.9470588235294117],"matthews_correlation":[0.8933996344249813],"average_precision_score_weighted":[0.9951767676767677],"f1_score_macro":[0.9443434979081433],"recall_score_micro":[0.9470588235294117],"precision_score_macro":[0.9488721001221002],"recall_score_macro":[0.9448611111111112],"average_precision_score_micro":[0.9922659012005214],"AUC_macro":[0.9944444444444442],"f1_score_micro":[0.9470588235294117],"balanced_accuracy":[0.9448611111111112],"average_precision_score_macro":[0.9951781705948374],"precision_score_weighted":[0.9509286791639733],"norm_macro_recall":[0.8897222222222222],"weighted_accuracy":[0.9485615180575392]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_19":{"norm_macro_recall":[0.9272222222222222],"AUC_micro":[0.9910034602076123],"recall_score_macro":[0.9636111111111111],"precision_score_micro":[0.9647058823529413],"AUC_weighted":[1.0],"recall_score_micro":[0.9647058823529413],"AUC_macro":[1.0],"f1_score_macro":[0.96194798707223],"average_precision_score_macro":[1.0],"balanced_accuracy":[0.9636111111111111],"log_loss":[0.15028960298689392],"f1_score_micro":[0.9647058823529413],"precision_score_macro":[0.9686285936285935],"weighted_accuracy":[0.9651132421954702],"precision_score_weighted":[0.9716051921934274],"matthews_correlation":[0.9318544735034127],"average_precision_score_weighted":[1.0],"recall_score_weighted":[0.9647058823529413],"f1_score_weighted":[0.9642647174395729],"accuracy":[0.9647058823529413],"average_precision_score_micro":[0.9918902778934312]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_21":{"balanced_accuracy":[0.9629166666666666],"recall_score_macro":[0.9629166666666666],"AUC_weighted":[0.9986111111111111],"AUC_micro":[0.9965397923875432],"precision_score_micro":[0.9647058823529413],"weighted_accuracy":[0.965802897367884],"matthews_correlation":[0.928604474895795],"average_precision_score_weighted":[0.9987581699346405],"recall_score_micro":[0.9647058823529413],"recall_score_weighted":[0.9647058823529413],"f1_score_micro":[0.9647058823529413],"f1_score_weighted":[0.9645545351210313],"f1_score_macro":[0.9621139657444007],"AUC_macro":[0.9986111111111111],"precision_score_macro":[0.9660149572649572],"log_loss":[0.10119714890899575],"precision_score_weighted":[0.9684917043740573],"average_precision_score_micro":[0.9968008255933952],"average_precision_score_macro":[0.99875],"accuracy":[0.9647058823529413],"norm_macro_recall":[0.9258333333333333]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_23":{"accuracy":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"average_precision_score_macro":[1.0],"f1_score_weighted":[0.9764009403497894],"AUC_macro":[1.0],"balanced_accuracy":[0.9747222222222222],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"log_loss":[0.07451981468445137],"recall_score_macro":[0.9747222222222222],"norm_macro_recall":[0.9494444444444443],"precision_score_weighted":[0.9792106586224232],"average_precision_score_weighted":[1.0],"f1_score_micro":[0.9764705882352942],"AUC_weighted":[1.0],"f1_score_macro":[0.9739603709731586],"AUC_micro":[0.9986159169550172],"precision_score_macro":[0.9767094017094017],"matthews_correlation":[0.9511123000100223],"precision_score_micro":[0.9764705882352942]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_18":{"log_loss":[0.12424090632583987],"recall_score_micro":[0.9705882352941178],"AUC_macro":[0.9986111111111111],"precision_score_macro":[0.9704594017094017],"average_precision_score_micro":[0.996477594649831],"f1_score_micro":[0.9705882352941178],"AUC_micro":[0.9961937716262976],"recall_score_weighted":[0.9705882352941178],"weighted_accuracy":[0.9720097939196082],"matthews_correlation":[0.9386123000100224],"norm_macro_recall":[0.9369444444444444],"AUC_weighted":[0.9986111111111111],"recall_score_macro":[0.9684722222222222],"f1_score_weighted":[0.970518587408613],"precision_score_micro":[0.9705882352941178],"average_precision_score_weighted":[0.9987581699346405],"balanced_accuracy":[0.9684722222222222],"average_precision_score_macro":[0.99875],"precision_score_weighted":[0.9726747109100049],"f1_score_macro":[0.9680371683587795],"accuracy":[0.9705882352941178]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_25":{"balanced_accuracy":[0.9518055555555556],"matthews_correlation":[0.9082433623923014],"average_precision_score_micro":[0.9931734468813325],"accuracy":[0.9529411764705884],"recall_score_macro":[0.9518055555555556],"AUC_weighted":[0.9944444444444445],"recall_score_weighted":[0.9529411764705884],"average_precision_score_macro":[0.9951781705948374],"f1_score_weighted":[0.95250001155722],"average_precision_score_weighted":[0.9951767676767677],"log_loss":[0.1563035317332711],"norm_macro_recall":[0.9036111111111111],"precision_score_macro":[0.9568230380730383],"precision_score_micro":[0.9529411764705884],"AUC_micro":[0.9923875432525952],"f1_score_macro":[0.9501424315166744],"AUC_macro":[0.9944444444444442],"weighted_accuracy":[0.9533891042644358],"f1_score_micro":[0.9529411764705884],"recall_score_micro":[0.9529411764705884],"precision_score_weighted":[0.9598404863110745]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_32":{"f1_score_macro":[0.979842723914335],"precision_score_macro":[0.9822649572649572],"precision_score_micro":[0.9823529411764707],"average_precision_score_weighted":[1.0],"log_loss":[0.10256983559515873],"norm_macro_recall":[0.9605555555555554],"recall_score_weighted":[0.9823529411764707],"accuracy":[0.9823529411764707],"AUC_micro":[0.998961937716263],"precision_score_weighted":[0.9844394167923578],"f1_score_micro":[0.9823529411764707],"AUC_macro":[1.0],"average_precision_score_micro":[0.9990196078431373],"recall_score_macro":[0.9802777777777777],"balanced_accuracy":[0.9802777777777777],"f1_score_weighted":[0.9822832932909659],"matthews_correlation":[0.9622234111211334],"weighted_accuracy":[0.9837339318506426],"recall_score_micro":[0.9823529411764707],"average_precision_score_macro":[1.0],"AUC_weighted":[1.0]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_39":{"average_precision_score_macro":[1.0],"f1_score_weighted":[0.9763596606800269],"accuracy":[0.9764705882352942],"precision_score_macro":[0.9772649572649572],"recall_score_micro":[0.9764705882352942],"AUC_weighted":[1.0],"precision_score_weighted":[0.979145299145299],"weighted_accuracy":[0.9782166904713323],"norm_macro_recall":[0.9480555555555554],"f1_score_micro":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"log_loss":[0.11612823182082159],"matthews_correlation":[0.9509646078676276],"f1_score_macro":[0.9738778116336333],"recall_score_weighted":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"average_precision_score_weighted":[1.0],"recall_score_macro":[0.9740277777777777],"balanced_accuracy":[0.9740277777777777],"AUC_macro":[1.0],"AUC_micro":[0.9986159169550172]},"087c0565-8aa8-4e36-bb34-3be30f0e5fd3_38":{"AUC_micro":[0.9986159169550172],"log_loss":[0.06556415778554234],"AUC_weighted":[1.0],"precision_score_macro":[0.9767094017094017],"f1_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"recall_score_micro":[0.9764705882352942],"average_precision_score_weighted":[1.0],"weighted_accuracy":[0.9775270352989185],"matthews_correlation":[0.9511123000100223],"AUC_macro":[1.0],"average_precision_score_micro":[0.9986928104575163],"precision_score_micro":[0.9764705882352942],"average_precision_score_macro":[1.0],"f1_score_weighted":[0.9764009403497894],"accuracy":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"norm_macro_recall":[0.9494444444444443],"precision_score_weighted":[0.9792106586224232],"recall_score_weighted":[0.9764705882352942]}}