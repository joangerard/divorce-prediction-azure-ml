{"8225b235-bbc9-4c45-907f-aadd86c28980_27":{"recall_score_macro":[0.9747222222222222],"recall_score_weighted":[0.9764705882352942],"average_precision_score_macro":[0.99875],"precision_score_macro":[0.9767094017094017],"recall_score_micro":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"log_loss":[0.0740931194067871],"AUC_macro":[0.9986111111111111],"f1_score_weighted":[0.9764009403497894],"precision_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"AUC_weighted":[0.9986111111111111],"accuracy":[0.9764705882352942],"AUC_micro":[0.9979238754325259],"f1_score_macro":[0.9739603709731586],"average_precision_score_weighted":[0.9987581699346405],"norm_macro_recall":[0.9494444444444443],"weighted_accuracy":[0.9775270352989185],"average_precision_score_micro":[0.9980543920354521],"matthews_correlation":[0.9511123000100223],"precision_score_weighted":[0.9792106586224232]},"8225b235-bbc9-4c45-907f-aadd86c28980_32":{"recall_score_weighted":[0.9235294117647059],"average_precision_score_micro":[0.9652821257691876],"AUC_macro":[0.9730357142857142],"f1_score_micro":[0.9235294117647059],"norm_macro_recall":[0.8375396825396825],"weighted_accuracy":[0.9274414069721425],"AUC_micro":[0.9712802768166089],"precision_score_micro":[0.9235294117647059],"average_precision_score_weighted":[0.9633706460782585],"precision_score_macro":[0.9308923021423021],"f1_score_weighted":[0.9225986315474806],"f1_score_macro":[0.9194044122260235],"AUC_weighted":[0.9730357142857142],"balanced_accuracy":[0.9187698412698413],"recall_score_micro":[0.9235294117647059],"log_loss":[0.36693524364938923],"average_precision_score_macro":[0.9616711752526703],"precision_score_weighted":[0.9315644486232723],"recall_score_macro":[0.9187698412698413],"matthews_correlation":[0.8490339467284859],"accuracy":[0.9235294117647059]},"8225b235-bbc9-4c45-907f-aadd86c28980_16":{"precision_score_weighted":[0.9792106586224232],"matthews_correlation":[0.9511123000100223],"weighted_accuracy":[0.9775270352989185],"average_precision_score_weighted":[1.0],"recall_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"balanced_accuracy":[0.9747222222222222],"AUC_weighted":[1.0],"norm_macro_recall":[0.9494444444444443],"precision_score_micro":[0.9764705882352942],"average_precision_score_macro":[1.0],"AUC_micro":[0.9986159169550172],"AUC_macro":[1.0],"f1_score_micro":[0.9764705882352942],"log_loss":[0.061556207339617766],"recall_score_weighted":[0.9764705882352942],"accuracy":[0.9764705882352942],"average_precision_score_micro":[0.9986928104575163],"precision_score_macro":[0.9767094017094017],"f1_score_weighted":[0.9764009403497894],"recall_score_macro":[0.9747222222222222]},"8225b235-bbc9-4c45-907f-aadd86c28980_26":{"f1_score_micro":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"recall_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"accuracy":[0.9764705882352942],"f1_score_weighted":[0.9764009403497894],"average_precision_score_micro":[0.9986928104575163],"balanced_accuracy":[0.9747222222222222],"AUC_macro":[1.0],"matthews_correlation":[0.9511123000100223],"log_loss":[0.04796118582822523],"precision_score_macro":[0.9767094017094017],"AUC_micro":[0.9986159169550172],"recall_score_weighted":[0.9764705882352942],"average_precision_score_weighted":[1.0],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"precision_score_micro":[0.9764705882352942],"norm_macro_recall":[0.9494444444444443],"AUC_weighted":[1.0]},"8225b235-bbc9-4c45-907f-aadd86c28980_34":{"average_precision_score_micro":[0.9986928104575163],"precision_score_macro":[0.9767094017094017],"AUC_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"norm_macro_recall":[0.9494444444444443],"AUC_micro":[0.9986159169550172],"f1_score_weighted":[0.9764009403497894],"precision_score_weighted":[0.9792106586224232],"log_loss":[0.0637632951468783],"average_precision_score_weighted":[1.0],"average_precision_score_macro":[1.0],"AUC_weighted":[1.0],"recall_score_macro":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"precision_score_micro":[0.9764705882352942],"accuracy":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"recall_score_weighted":[0.9764705882352942]},"8225b235-bbc9-4c45-907f-aadd86c28980_31":{"recall_score_micro":[0.9764705882352942],"norm_macro_recall":[0.9494444444444443],"precision_score_weighted":[0.9792106586224232],"balanced_accuracy":[0.9747222222222222],"precision_score_macro":[0.9767094017094017],"f1_score_weighted":[0.9764009403497894],"AUC_macro":[0.9986111111111111],"matthews_correlation":[0.9511123000100223],"AUC_weighted":[0.9986111111111111],"average_precision_score_micro":[0.9980543920354521],"average_precision_score_weighted":[0.9987581699346405],"precision_score_micro":[0.9764705882352942],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"average_precision_score_macro":[0.99875],"AUC_micro":[0.9979238754325259],"f1_score_macro":[0.9739603709731586],"accuracy":[0.9764705882352942],"log_loss":[0.15385718581289248],"f1_score_micro":[0.9764705882352942]},"8225b235-bbc9-4c45-907f-aadd86c28980_22":{"average_precision_score_weighted":[0.995258467023173],"AUC_macro":[0.9944444444444445],"precision_score_macro":[0.9573785936285937],"precision_score_micro":[0.9529411764705884],"recall_score_micro":[0.9529411764705884],"average_precision_score_macro":[0.9952553310886645],"AUC_weighted":[0.9944444444444445],"AUC_micro":[0.9916955017301037],"precision_score_weighted":[0.9597751268339504],"average_precision_score_micro":[0.9926045614324162],"f1_score_macro":[0.950059872177149],"accuracy":[0.9529411764705884],"matthews_correlation":[0.9080956702499069],"recall_score_weighted":[0.9529411764705884],"recall_score_macro":[0.9511111111111111],"log_loss":[0.29889844694038553],"norm_macro_recall":[0.9022222222222223],"f1_score_micro":[0.9529411764705884],"weighted_accuracy":[0.9540787594368496],"balanced_accuracy":[0.9511111111111111],"f1_score_weighted":[0.9524587318874571]},"8225b235-bbc9-4c45-907f-aadd86c28980_29":{"weighted_accuracy":[0.9720097939196082],"average_precision_score_macro":[0.9975000000000002],"recall_score_micro":[0.9705882352941178],"AUC_macro":[0.9972222222222221],"matthews_correlation":[0.9386123000100224],"precision_score_macro":[0.9704594017094017],"recall_score_macro":[0.9684722222222222],"recall_score_weighted":[0.9705882352941178],"average_precision_score_weighted":[0.997516339869281],"log_loss":[0.13775454109486338],"f1_score_macro":[0.9680371683587795],"precision_score_weighted":[0.9726747109100049],"balanced_accuracy":[0.9684722222222222],"average_precision_score_micro":[0.9958473425489908],"precision_score_micro":[0.9705882352941178],"f1_score_weighted":[0.970518587408613],"f1_score_micro":[0.9705882352941178],"norm_macro_recall":[0.9369444444444444],"accuracy":[0.9705882352941178],"AUC_micro":[0.9955017301038062],"AUC_weighted":[0.9972222222222221]},"8225b235-bbc9-4c45-907f-aadd86c28980_25":{"AUC_macro":[1.0],"f1_score_weighted":[0.9881656462321423],"precision_score_micro":[0.9882352941176471],"weighted_accuracy":[0.9899408284023667],"recall_score_macro":[0.9858333333333335],"recall_score_micro":[0.9882352941176471],"average_precision_score_micro":[0.9993464052287582],"recall_score_weighted":[0.9882352941176471],"log_loss":[0.16215353599664167],"matthews_correlation":[0.9733345222322445],"precision_score_macro":[0.9878205128205128],"balanced_accuracy":[0.9858333333333335],"average_precision_score_macro":[1.0],"average_precision_score_weighted":[1.0],"norm_macro_recall":[0.9716666666666667],"AUC_weighted":[1.0],"f1_score_micro":[0.9882352941176471],"precision_score_weighted":[0.9896681749622926],"AUC_micro":[0.9993079584775086],"accuracy":[0.9882352941176471],"f1_score_macro":[0.9857250768555117]},"8225b235-bbc9-4c45-907f-aadd86c28980_30":{"AUC_macro":[0.9949999999999999],"log_loss":[0.5026820034906467],"f1_score_weighted":[0.9822832932909659],"precision_score_weighted":[0.9844394167923578],"average_precision_score_macro":[0.995203477078477],"f1_score_micro":[0.9823529411764707],"recall_score_weighted":[0.9823529411764707],"recall_score_micro":[0.9823529411764707],"average_precision_score_micro":[0.9971201323666723],"precision_score_micro":[0.9823529411764707],"AUC_weighted":[0.9949999999999999],"accuracy":[0.9823529411764707],"weighted_accuracy":[0.9837339318506426],"precision_score_macro":[0.9822649572649572],"matthews_correlation":[0.9622234111211334],"norm_macro_recall":[0.9605555555555554],"f1_score_macro":[0.979842723914335],"average_precision_score_weighted":[0.9963166735225559],"AUC_micro":[0.9968858131487888],"balanced_accuracy":[0.9802777777777777],"recall_score_macro":[0.9802777777777777]},"8225b235-bbc9-4c45-907f-aadd86c28980_28":{"AUC_weighted":[1.0],"precision_score_weighted":[0.9792106586224232],"average_precision_score_micro":[0.9986928104575163],"balanced_accuracy":[0.9747222222222222],"log_loss":[0.056092368252281075],"accuracy":[0.9764705882352942],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9775270352989185],"f1_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"precision_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"AUC_micro":[0.9986159169550172],"average_precision_score_weighted":[1.0],"AUC_macro":[1.0],"norm_macro_recall":[0.9494444444444443],"recall_score_macro":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"f1_score_weighted":[0.9764009403497894]},"8225b235-bbc9-4c45-907f-aadd86c28980_35":{"AUC_macro":[0.5],"average_precision_score_weighted":[0.5307958477508651],"matthews_correlation":[0.0],"accuracy":[0.46470588235294114],"AUC_weighted":[0.5],"f1_score_macro":[0.3127953942609115],"log_loss":[0.6931471805599452],"precision_score_micro":[0.46470588235294114],"f1_score_micro":[0.46470588235294114],"norm_macro_recall":[0.0],"recall_score_weighted":[0.46470588235294114],"precision_score_macro":[0.23235294117647057],"f1_score_weighted":[0.3038209761840594],"recall_score_micro":[0.46470588235294114],"precision_score_weighted":[0.23010380622837373],"AUC_micro":[0.46470588235294114],"weighted_accuracy":[0.43689889339115845],"balanced_accuracy":[0.5],"average_precision_score_micro":[0.4977508650519031],"average_precision_score_macro":[0.5],"recall_score_macro":[0.5]},"8225b235-bbc9-4c45-907f-aadd86c28980_37":{"precision_score_weighted":[0.9726747109100049],"AUC_micro":[0.9961937716262976],"accuracy":[0.9705882352941178],"average_precision_score_macro":[0.99875],"f1_score_weighted":[0.970518587408613],"matthews_correlation":[0.9386123000100224],"precision_score_macro":[0.9704594017094017],"balanced_accuracy":[0.9684722222222222],"weighted_accuracy":[0.9720097939196082],"AUC_weighted":[0.9986111111111111],"recall_score_micro":[0.9705882352941178],"AUC_macro":[0.9986111111111111],"recall_score_weighted":[0.9705882352941178],"f1_score_macro":[0.9680371683587795],"log_loss":[0.1443007836572901],"recall_score_macro":[0.9684722222222222],"f1_score_micro":[0.9705882352941178],"norm_macro_recall":[0.9369444444444444],"average_precision_score_micro":[0.996477594649831],"average_precision_score_weighted":[0.9987581699346405],"precision_score_micro":[0.9705882352941178]},"8225b235-bbc9-4c45-907f-aadd86c28980_41":{"balanced_accuracy":[0.9747222222222222],"f1_score_micro":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"matthews_correlation":[0.9511123000100223],"precision_score_macro":[0.9767094017094017],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"AUC_macro":[1.0],"AUC_micro":[0.9986159169550172],"f1_score_weighted":[0.9764009403497894],"average_precision_score_micro":[0.9986928104575163],"log_loss":[0.09653247611781315],"AUC_weighted":[1.0],"precision_score_micro":[0.9764705882352942],"average_precision_score_macro":[1.0],"precision_score_weighted":[0.9792106586224232],"average_precision_score_weighted":[1.0],"norm_macro_recall":[0.9494444444444443],"recall_score_micro":[0.9764705882352942],"accuracy":[0.9764705882352942]},"8225b235-bbc9-4c45-907f-aadd86c28980_44":{"log_loss":[0.1643974398502802],"recall_score_micro":[0.9882352941176471],"AUC_micro":[0.9993079584775086],"AUC_macro":[1.0],"accuracy":[0.9882352941176471],"precision_score_weighted":[0.9896681749622926],"norm_macro_recall":[0.9716666666666667],"f1_score_macro":[0.9857250768555117],"precision_score_micro":[0.9882352941176471],"matthews_correlation":[0.9733345222322445],"recall_score_macro":[0.9858333333333335],"f1_score_micro":[0.9882352941176471],"recall_score_weighted":[0.9882352941176471],"AUC_weighted":[1.0],"average_precision_score_weighted":[1.0],"precision_score_macro":[0.9878205128205128],"balanced_accuracy":[0.9858333333333335],"f1_score_weighted":[0.9881656462321423],"average_precision_score_micro":[0.9993464052287582],"weighted_accuracy":[0.9899408284023667],"average_precision_score_macro":[1.0]},"8225b235-bbc9-4c45-907f-aadd86c28980_3":{"recall_score_macro":[0.9784722222222223],"AUC_weighted":[0.9986111111111111],"balanced_accuracy":[0.9784722222222223],"f1_score_micro":[0.9764705882352942],"average_precision_score_macro":[0.99875],"accuracy":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9781045751633988],"log_loss":[0.283771576708101],"AUC_macro":[0.9986111111111111],"matthews_correlation":[0.9526785151252903],"norm_macro_recall":[0.9569444444444445],"precision_score_macro":[0.9743055555555555],"precision_score_micro":[0.9764705882352942],"weighted_accuracy":[0.9749683738012651],"average_precision_score_weighted":[0.9987581699346405],"average_precision_score_micro":[0.9974351969890124],"AUC_micro":[0.9972318339100348],"recall_score_weighted":[0.9764705882352942],"f1_score_macro":[0.9755927239143352],"f1_score_weighted":[0.9766100906765869]},"8225b235-bbc9-4c45-907f-aadd86c28980_38":{"matthews_correlation":[0.9386123000100224],"accuracy":[0.9705882352941178],"weighted_accuracy":[0.9720097939196082],"average_precision_score_macro":[0.9975000000000002],"precision_score_micro":[0.9705882352941178],"precision_score_weighted":[0.9726747109100049],"norm_macro_recall":[0.9369444444444444],"average_precision_score_micro":[0.9958689688465686],"precision_score_macro":[0.9704594017094017],"f1_score_micro":[0.9705882352941178],"recall_score_weighted":[0.9705882352941178],"AUC_macro":[0.9972222222222221],"log_loss":[0.17023895259441435],"average_precision_score_weighted":[0.997516339869281],"f1_score_macro":[0.9680371683587795],"recall_score_micro":[0.9705882352941178],"AUC_weighted":[0.9972222222222221],"f1_score_weighted":[0.970518587408613],"AUC_micro":[0.9955017301038062],"recall_score_macro":[0.9684722222222222],"balanced_accuracy":[0.9684722222222222]},"8225b235-bbc9-4c45-907f-aadd86c28980_4":{"average_precision_score_micro":[0.996477594649831],"accuracy":[0.9705882352941178],"f1_score_weighted":[0.970518587408613],"log_loss":[0.14099732417688277],"matthews_correlation":[0.9386123000100224],"AUC_weighted":[0.9986111111111111],"average_precision_score_macro":[0.99875],"precision_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"precision_score_weighted":[0.9726747109100049],"recall_score_macro":[0.9684722222222222],"recall_score_micro":[0.9705882352941178],"f1_score_macro":[0.9680371683587795],"norm_macro_recall":[0.9369444444444444],"balanced_accuracy":[0.9684722222222222],"recall_score_weighted":[0.9705882352941178],"AUC_micro":[0.9961937716262976],"average_precision_score_weighted":[0.9987581699346405],"weighted_accuracy":[0.9720097939196082],"AUC_macro":[0.9986111111111111],"precision_score_macro":[0.9704594017094017]},"8225b235-bbc9-4c45-907f-aadd86c28980_7":{"AUC_macro":[1.0],"accuracy":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"precision_score_macro":[0.9767094017094017],"weighted_accuracy":[0.9775270352989185],"average_precision_score_micro":[0.9986928104575163],"f1_score_micro":[0.9764705882352942],"log_loss":[0.048804713895068776],"average_precision_score_weighted":[1.0],"AUC_micro":[0.9986159169550172],"f1_score_macro":[0.9739603709731586],"norm_macro_recall":[0.9494444444444443],"AUC_weighted":[1.0],"precision_score_micro":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"average_precision_score_macro":[1.0],"f1_score_weighted":[0.9764009403497894],"recall_score_macro":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222]},"8225b235-bbc9-4c45-907f-aadd86c28980_5":{"AUC_weighted":[0.9944444444444445],"AUC_micro":[0.9930795847750865],"AUC_macro":[0.9944444444444445],"norm_macro_recall":[0.9230555555555556],"recall_score_micro":[0.9647058823529413],"average_precision_score_weighted":[0.9951767676767677],"weighted_accuracy":[0.9666965925321364],"log_loss":[0.3625386927838666],"balanced_accuracy":[0.9615277777777779],"recall_score_weighted":[0.9647058823529413],"precision_score_weighted":[0.9676607053077643],"average_precision_score_micro":[0.9938654884038238],"average_precision_score_macro":[0.9951781705948374],"accuracy":[0.9647058823529413],"matthews_correlation":[0.9297577003309744],"precision_score_macro":[0.9684554334554335],"f1_score_micro":[0.9647058823529413],"recall_score_macro":[0.9615277777777779],"precision_score_micro":[0.9647058823529413],"f1_score_weighted":[0.9643333333333335],"f1_score_macro":[0.9629509803921568]},"8225b235-bbc9-4c45-907f-aadd86c28980_6":{"average_precision_score_macro":[0.9967628205128205],"AUC_micro":[0.996885813148789],"recall_score_micro":[0.9705882352941178],"average_precision_score_weighted":[0.997325289089995],"balanced_accuracy":[0.9684722222222222],"accuracy":[0.9705882352941178],"recall_score_macro":[0.9684722222222222],"AUC_weighted":[0.9969444444444445],"precision_score_weighted":[0.9726747109100049],"f1_score_weighted":[0.970518587408613],"recall_score_weighted":[0.9705882352941178],"precision_score_micro":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"average_precision_score_micro":[0.9971083996033914],"AUC_macro":[0.9969444444444445],"weighted_accuracy":[0.9720097939196082],"precision_score_macro":[0.9704594017094017],"log_loss":[0.2590568021043464],"f1_score_macro":[0.9680371683587795],"matthews_correlation":[0.9386123000100224],"norm_macro_recall":[0.9369444444444444]},"8225b235-bbc9-4c45-907f-aadd86c28980_40":{"average_precision_score_weighted":[0.5307958477508651],"average_precision_score_micro":[0.4683391003460208],"balanced_accuracy":[0.5],"f1_score_micro":[0.40588235294117647],"weighted_accuracy":[0.33131227841462296],"average_precision_score_macro":[0.5],"precision_score_weighted":[0.171280276816609],"f1_score_weighted":[0.23917030028794736],"AUC_weighted":[0.5],"recall_score_weighted":[0.40588235294117647],"norm_macro_recall":[0.0],"matthews_correlation":[0.0],"f1_score_macro":[0.2862972027972027],"precision_score_macro":[0.20294117647058824],"log_loss":[0.6995999241779065],"recall_score_macro":[0.5],"precision_score_micro":[0.40588235294117647],"accuracy":[0.40588235294117647],"AUC_macro":[0.5],"AUC_micro":[0.40588235294117647],"recall_score_micro":[0.40588235294117647]},"8225b235-bbc9-4c45-907f-aadd86c28980_36":{"matthews_correlation":[0.9386123000100224],"weighted_accuracy":[0.9720097939196082],"AUC_weighted":[0.9986111111111111],"precision_score_weighted":[0.9726747109100049],"f1_score_micro":[0.9705882352941178],"AUC_macro":[0.9986111111111111],"average_precision_score_micro":[0.9977468180254558],"balanced_accuracy":[0.9684722222222222],"recall_score_micro":[0.9705882352941178],"f1_score_weighted":[0.970518587408613],"AUC_micro":[0.9975778546712804],"recall_score_macro":[0.9684722222222222],"average_precision_score_macro":[0.99875],"accuracy":[0.9705882352941178],"precision_score_micro":[0.9705882352941178],"norm_macro_recall":[0.9369444444444444],"f1_score_macro":[0.9680371683587795],"recall_score_weighted":[0.9705882352941178],"average_precision_score_weighted":[0.9987581699346405],"precision_score_macro":[0.9704594017094017],"log_loss":[0.09371839400940492]},"8225b235-bbc9-4c45-907f-aadd86c28980_39":{"precision_score_micro":[0.9764705882352942],"average_precision_score_weighted":[0.9987581699346405],"log_loss":[0.06686476455125138],"recall_score_macro":[0.9740277777777779],"f1_score_macro":[0.9739195212999562],"accuracy":[0.9764705882352942],"precision_score_weighted":[0.9779034690799397],"precision_score_macro":[0.9760149572649572],"norm_macro_recall":[0.9480555555555557],"matthews_correlation":[0.9497234111211335],"recall_score_micro":[0.9764705882352942],"balanced_accuracy":[0.9740277777777779],"recall_score_weighted":[0.9764705882352942],"average_precision_score_macro":[0.99875],"average_precision_score_micro":[0.9980736154110768],"AUC_weighted":[0.9986111111111111],"weighted_accuracy":[0.9782166904713323],"f1_score_micro":[0.9764705882352942],"AUC_micro":[0.997923875432526],"AUC_macro":[0.9986111111111111],"f1_score_weighted":[0.9764009403497894]},"8225b235-bbc9-4c45-907f-aadd86c28980_45":{"f1_score_micro":[0.9764705882352942],"f1_score_weighted":[0.9763596606800269],"AUC_micro":[0.9986159169550172],"precision_score_weighted":[0.979145299145299],"balanced_accuracy":[0.9740277777777777],"matthews_correlation":[0.9509646078676276],"recall_score_weighted":[0.9764705882352942],"recall_score_macro":[0.9740277777777777],"average_precision_score_macro":[1.0],"norm_macro_recall":[0.9480555555555554],"precision_score_micro":[0.9764705882352942],"weighted_accuracy":[0.9782166904713323],"average_precision_score_micro":[0.9986928104575163],"log_loss":[0.20823330407195875],"precision_score_macro":[0.9772649572649572],"accuracy":[0.9764705882352942],"average_precision_score_weighted":[1.0],"f1_score_macro":[0.9738778116336333],"recall_score_micro":[0.9764705882352942],"AUC_weighted":[1.0],"AUC_macro":[1.0]},"8225b235-bbc9-4c45-907f-aadd86c28980_15":{"recall_score_micro":[0.9823529411764707],"AUC_weighted":[0.9966666666666667],"log_loss":[0.07736804385301518],"precision_score_weighted":[0.9844394167923578],"f1_score_micro":[0.9823529411764707],"precision_score_micro":[0.9823529411764707],"recall_score_weighted":[0.9823529411764707],"precision_score_macro":[0.9822649572649572],"f1_score_weighted":[0.9822832932909659],"f1_score_macro":[0.979842723914335],"AUC_micro":[0.9975778546712804],"AUC_macro":[0.9966666666666667],"accuracy":[0.9823529411764707],"matthews_correlation":[0.9622234111211334],"norm_macro_recall":[0.9605555555555554],"average_precision_score_macro":[0.9957380952380952],"average_precision_score_weighted":[0.9970028011204481],"weighted_accuracy":[0.9837339318506426],"balanced_accuracy":[0.9802777777777777],"average_precision_score_micro":[0.9977503844675125],"recall_score_macro":[0.9802777777777777]},"8225b235-bbc9-4c45-907f-aadd86c28980_20":{"average_precision_score_macro":[1.0],"AUC_micro":[0.9837370242214533],"recall_score_macro":[0.935138888888889],"average_precision_score_micro":[0.9853766863887179],"recall_score_micro":[0.9352941176470588],"AUC_macro":[1.0],"f1_score_weighted":[0.9338032697025833],"f1_score_macro":[0.931697360505814],"log_loss":[0.17912064723367957],"f1_score_micro":[0.9352941176470588],"average_precision_score_weighted":[1.0],"weighted_accuracy":[0.9347684146092634],"recall_score_weighted":[0.9352941176470588],"matthews_correlation":[0.8814537321949253],"accuracy":[0.9352941176470588],"norm_macro_recall":[0.8702777777777777],"AUC_weighted":[1.0],"precision_score_macro":[0.946961926961927],"precision_score_micro":[0.9352941176470588],"precision_score_weighted":[0.9506248000365648],"balanced_accuracy":[0.935138888888889]},"8225b235-bbc9-4c45-907f-aadd86c28980_14":{"recall_score_micro":[0.9470588235294117],"f1_score_micro":[0.9470588235294117],"precision_score_macro":[0.9488721001221002],"average_precision_score_macro":[0.9951781705948374],"log_loss":[0.32475337134579546],"recall_score_weighted":[0.9470588235294117],"weighted_accuracy":[0.9485615180575392],"recall_score_macro":[0.9448611111111112],"norm_macro_recall":[0.8897222222222222],"AUC_weighted":[0.9944444444444445],"accuracy":[0.9470588235294117],"matthews_correlation":[0.8933996344249813],"average_precision_score_micro":[0.9922659012005214],"f1_score_macro":[0.9443434979081433],"precision_score_weighted":[0.9509286791639733],"precision_score_micro":[0.9470588235294117],"AUC_macro":[0.9944444444444442],"average_precision_score_weighted":[0.9951767676767677],"f1_score_weighted":[0.9467844972813341],"balanced_accuracy":[0.9448611111111112],"AUC_micro":[0.9913494809688583]},"8225b235-bbc9-4c45-907f-aadd86c28980_9":{"AUC_weighted":[0.9972222222222221],"f1_score_macro":[0.9553945981554678],"norm_macro_recall":[0.9175000000000001],"recall_score_macro":[0.95875],"average_precision_score_macro":[0.9975000000000002],"f1_score_micro":[0.9588235294117646],"AUC_micro":[0.9941176470588236],"matthews_correlation":[0.9160052122433078],"weighted_accuracy":[0.9587023056519077],"precision_score_macro":[0.9576816239316239],"average_precision_score_micro":[0.9946133788912883],"AUC_macro":[0.9972222222222221],"balanced_accuracy":[0.95875],"precision_score_micro":[0.9588235294117646],"recall_score_weighted":[0.9588235294117646],"recall_score_micro":[0.9588235294117646],"precision_score_weighted":[0.9635897435897436],"average_precision_score_weighted":[0.997516339869281],"log_loss":[0.3024174996529746],"f1_score_weighted":[0.9588116846211475],"accuracy":[0.9588235294117646]},"8225b235-bbc9-4c45-907f-aadd86c28980_0":{"matthews_correlation":[0.9511123000100223],"norm_macro_recall":[0.9494444444444443],"AUC_macro":[0.9969444444444445],"f1_score_macro":[0.9739603709731586],"precision_score_weighted":[0.9792106586224232],"average_precision_score_micro":[0.9961467502377627],"balanced_accuracy":[0.9747222222222222],"precision_score_micro":[0.9764705882352942],"weighted_accuracy":[0.9775270352989185],"log_loss":[0.09169236604145156],"recall_score_macro":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"f1_score_weighted":[0.9764009403497894],"recall_score_weighted":[0.9764705882352942],"accuracy":[0.9764705882352942],"average_precision_score_macro":[0.9967628205128205],"f1_score_micro":[0.9764705882352942],"AUC_micro":[0.9958477508650517],"precision_score_macro":[0.9767094017094017],"average_precision_score_weighted":[0.997325289089995],"AUC_weighted":[0.9969444444444445]},"8225b235-bbc9-4c45-907f-aadd86c28980_24":{"average_precision_score_micro":[0.9955164981369224],"accuracy":[0.9764705882352942],"AUC_micro":[0.9951557093425605],"average_precision_score_macro":[0.995203477078477],"f1_score_weighted":[0.9764009403497894],"log_loss":[0.10077952083922644],"balanced_accuracy":[0.9747222222222222],"precision_score_weighted":[0.9792106586224232],"recall_score_micro":[0.9764705882352942],"recall_score_macro":[0.9747222222222222],"average_precision_score_weighted":[0.9963166735225559],"AUC_weighted":[0.9949999999999999],"norm_macro_recall":[0.9494444444444443],"AUC_macro":[0.9949999999999999],"f1_score_macro":[0.9739603709731586],"precision_score_macro":[0.9767094017094017],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"f1_score_micro":[0.9764705882352942],"precision_score_micro":[0.9764705882352942]},"8225b235-bbc9-4c45-907f-aadd86c28980_33":{"average_precision_score_weighted":[0.9951767676767677],"AUC_weighted":[0.9944444444444445],"AUC_micro":[0.9871972318339098],"accuracy":[0.9235294117647059],"weighted_accuracy":[0.9257020002766181],"recall_score_macro":[0.9216269841269842],"average_precision_score_macro":[0.9951781705948374],"f1_score_macro":[0.9207328615544726],"balanced_accuracy":[0.9216269841269842],"f1_score_weighted":[0.9227215935527957],"precision_score_macro":[0.9301930014430015],"recall_score_micro":[0.9235294117647059],"precision_score_weighted":[0.9316467192937781],"matthews_correlation":[0.851373644794229],"log_loss":[0.13708142830195325],"average_precision_score_micro":[0.9884592645107577],"f1_score_micro":[0.9235294117647059],"norm_macro_recall":[0.8432539682539681],"AUC_macro":[0.9944444444444445],"precision_score_micro":[0.9235294117647059],"recall_score_weighted":[0.9235294117647059]},"8225b235-bbc9-4c45-907f-aadd86c28980_2":{"matthews_correlation":[0.9511123000100223],"precision_score_micro":[0.9764705882352942],"AUC_macro":[1.0],"recall_score_micro":[0.9764705882352942],"accuracy":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"average_precision_score_macro":[1.0],"AUC_micro":[0.9979238754325259],"norm_macro_recall":[0.9494444444444443],"recall_score_macro":[0.9747222222222222],"weighted_accuracy":[0.9775270352989185],"recall_score_weighted":[0.9764705882352942],"average_precision_score_micro":[0.9980543920354519],"precision_score_macro":[0.9767094017094017],"f1_score_macro":[0.9739603709731586],"f1_score_weighted":[0.9764009403497894],"AUC_weighted":[1.0],"log_loss":[0.09022909482724936],"balanced_accuracy":[0.9747222222222222],"average_precision_score_weighted":[1.0]},"8225b235-bbc9-4c45-907f-aadd86c28980_1":{"matthews_correlation":[0.9386123000100224],"accuracy":[0.9705882352941178],"precision_score_micro":[0.9705882352941178],"weighted_accuracy":[0.9720097939196082],"average_precision_score_weighted":[0.997325289089995],"recall_score_micro":[0.9705882352941178],"log_loss":[0.06953465307505337],"AUC_macro":[0.9969444444444445],"precision_score_weighted":[0.9726747109100049],"f1_score_micro":[0.9705882352941178],"f1_score_weighted":[0.970518587408613],"norm_macro_recall":[0.9369444444444444],"precision_score_macro":[0.9704594017094017],"f1_score_macro":[0.9680371683587795],"balanced_accuracy":[0.9684722222222222],"average_precision_score_macro":[0.9967628205128205],"AUC_weighted":[0.9969444444444445],"recall_score_weighted":[0.9705882352941178],"AUC_micro":[0.9955017301038062],"recall_score_macro":[0.9684722222222222],"average_precision_score_micro":[0.9958391762277665]},"8225b235-bbc9-4c45-907f-aadd86c28980_18":{"recall_score_macro":[0.9684722222222222],"matthews_correlation":[0.9386123000100224],"precision_score_weighted":[0.9726747109100049],"recall_score_micro":[0.9705882352941178],"AUC_macro":[0.9986111111111111],"weighted_accuracy":[0.9720097939196082],"precision_score_macro":[0.9704594017094017],"average_precision_score_weighted":[0.9987581699346405],"AUC_weighted":[0.9986111111111111],"precision_score_micro":[0.9705882352941178],"AUC_micro":[0.9961937716262976],"log_loss":[0.12424090632583987],"balanced_accuracy":[0.9684722222222222],"f1_score_macro":[0.9680371683587795],"average_precision_score_macro":[0.99875],"accuracy":[0.9705882352941178],"f1_score_micro":[0.9705882352941178],"average_precision_score_micro":[0.996477594649831],"f1_score_weighted":[0.970518587408613],"norm_macro_recall":[0.9369444444444444],"recall_score_weighted":[0.9705882352941178]},"8225b235-bbc9-4c45-907f-aadd86c28980_8":{"f1_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"balanced_accuracy":[0.9747222222222222],"accuracy":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"recall_score_micro":[0.9764705882352942],"average_precision_score_weighted":[1.0],"f1_score_weighted":[0.9764009403497894],"AUC_macro":[1.0],"log_loss":[0.0702554035389648],"f1_score_macro":[0.9739603709731586],"AUC_micro":[0.9979238754325259],"average_precision_score_micro":[0.9980543920354519],"norm_macro_recall":[0.9494444444444443],"AUC_weighted":[1.0],"recall_score_macro":[0.9747222222222222],"matthews_correlation":[0.9511123000100223],"precision_score_weighted":[0.9792106586224232],"average_precision_score_macro":[1.0],"precision_score_macro":[0.9767094017094017],"weighted_accuracy":[0.9775270352989185]},"8225b235-bbc9-4c45-907f-aadd86c28980_11":{"f1_score_macro":[0.9680371683587795],"f1_score_weighted":[0.970518587408613],"average_precision_score_micro":[0.9977468180254558],"precision_score_weighted":[0.9726747109100049],"AUC_weighted":[0.9986111111111111],"accuracy":[0.9705882352941178],"balanced_accuracy":[0.9684722222222222],"weighted_accuracy":[0.9720097939196082],"f1_score_micro":[0.9705882352941178],"average_precision_score_weighted":[0.9987581699346405],"average_precision_score_macro":[0.99875],"matthews_correlation":[0.9386123000100224],"AUC_macro":[0.9986111111111111],"precision_score_micro":[0.9705882352941178],"AUC_micro":[0.9975778546712804],"log_loss":[0.27928275608402325],"precision_score_macro":[0.9704594017094017],"recall_score_macro":[0.9684722222222222],"recall_score_weighted":[0.9705882352941178],"norm_macro_recall":[0.9369444444444444],"recall_score_micro":[0.9705882352941178]},"8225b235-bbc9-4c45-907f-aadd86c28980_10":{"weighted_accuracy":[0.9720097939196082],"precision_score_macro":[0.9704594017094017],"matthews_correlation":[0.9386123000100224],"f1_score_micro":[0.9705882352941178],"average_precision_score_weighted":[0.9987581699346405],"AUC_micro":[0.996885813148789],"accuracy":[0.9705882352941178],"AUC_weighted":[0.9986111111111111],"recall_score_weighted":[0.9705882352941178],"precision_score_weighted":[0.9726747109100049],"average_precision_score_macro":[0.99875],"average_precision_score_micro":[0.9971083996033914],"AUC_macro":[0.9986111111111111],"log_loss":[0.14233186299666456],"f1_score_macro":[0.9680371683587795],"recall_score_micro":[0.9705882352941178],"norm_macro_recall":[0.9369444444444444],"balanced_accuracy":[0.9684722222222222],"recall_score_macro":[0.9684722222222222],"f1_score_weighted":[0.970518587408613],"precision_score_micro":[0.9705882352941178]},"8225b235-bbc9-4c45-907f-aadd86c28980_12":{"balanced_accuracy":[0.9747222222222222],"recall_score_micro":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"f1_score_micro":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"accuracy":[0.9764705882352942],"AUC_micro":[0.9986159169550172],"recall_score_weighted":[0.9764705882352942],"average_precision_score_macro":[1.0],"norm_macro_recall":[0.9494444444444443],"recall_score_macro":[0.9747222222222222],"AUC_macro":[1.0],"f1_score_macro":[0.9739603709731586],"average_precision_score_weighted":[1.0],"log_loss":[0.08276036113345764],"f1_score_weighted":[0.9764009403497894],"weighted_accuracy":[0.9775270352989185],"AUC_weighted":[1.0],"precision_score_weighted":[0.9792106586224232],"average_precision_score_micro":[0.9986928104575163]},"8225b235-bbc9-4c45-907f-aadd86c28980_13":{"AUC_micro":[0.9986159169550172],"average_precision_score_micro":[0.9986928104575163],"precision_score_weighted":[0.9792106586224232],"log_loss":[0.041377260922129795],"accuracy":[0.9764705882352942],"AUC_macro":[1.0],"balanced_accuracy":[0.9747222222222222],"recall_score_weighted":[0.9764705882352942],"average_precision_score_macro":[1.0],"matthews_correlation":[0.9511123000100223],"average_precision_score_weighted":[1.0],"f1_score_micro":[0.9764705882352942],"precision_score_micro":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"AUC_weighted":[1.0],"norm_macro_recall":[0.9494444444444443],"recall_score_micro":[0.9764705882352942],"f1_score_weighted":[0.9764009403497894],"weighted_accuracy":[0.9775270352989185],"recall_score_macro":[0.9747222222222222],"precision_score_macro":[0.9767094017094017]},"8225b235-bbc9-4c45-907f-aadd86c28980_19":{"f1_score_micro":[0.9647058823529413],"precision_score_micro":[0.9647058823529413],"AUC_weighted":[1.0],"f1_score_weighted":[0.9642647174395729],"accuracy":[0.9647058823529413],"f1_score_macro":[0.96194798707223],"precision_score_weighted":[0.9716051921934274],"average_precision_score_macro":[1.0],"weighted_accuracy":[0.9651132421954702],"balanced_accuracy":[0.9636111111111111],"log_loss":[0.15471303379051465],"recall_score_macro":[0.9636111111111111],"average_precision_score_micro":[0.993061724314456],"norm_macro_recall":[0.9272222222222222],"matthews_correlation":[0.9318544735034127],"AUC_macro":[1.0],"precision_score_macro":[0.9686285936285935],"AUC_micro":[0.9923875432525952],"recall_score_weighted":[0.9647058823529413],"recall_score_micro":[0.9647058823529413],"average_precision_score_weighted":[1.0]},"8225b235-bbc9-4c45-907f-aadd86c28980_21":{"recall_score_micro":[0.9647058823529413],"recall_score_weighted":[0.9647058823529413],"norm_macro_recall":[0.9258333333333333],"AUC_weighted":[0.9986111111111111],"precision_score_weighted":[0.9684917043740573],"AUC_micro":[0.9965397923875432],"f1_score_micro":[0.9647058823529413],"recall_score_macro":[0.9629166666666666],"accuracy":[0.9647058823529413],"average_precision_score_macro":[0.99875],"average_precision_score_weighted":[0.9987581699346405],"weighted_accuracy":[0.965802897367884],"precision_score_macro":[0.9660149572649572],"f1_score_macro":[0.9621139657444007],"matthews_correlation":[0.928604474895795],"precision_score_micro":[0.9647058823529413],"balanced_accuracy":[0.9629166666666666],"AUC_macro":[0.9986111111111111],"f1_score_weighted":[0.9645545351210313],"average_precision_score_micro":[0.9968008255933952],"log_loss":[0.10119714890899575]},"8225b235-bbc9-4c45-907f-aadd86c28980_23":{"AUC_weighted":[1.0],"matthews_correlation":[0.9511123000100223],"log_loss":[0.07451981468445137],"precision_score_micro":[0.9764705882352942],"precision_score_macro":[0.9767094017094017],"weighted_accuracy":[0.9775270352989185],"f1_score_weighted":[0.9764009403497894],"AUC_micro":[0.9986159169550172],"AUC_macro":[1.0],"average_precision_score_weighted":[1.0],"balanced_accuracy":[0.9747222222222222],"norm_macro_recall":[0.9494444444444443],"recall_score_micro":[0.9764705882352942],"average_precision_score_macro":[1.0],"precision_score_weighted":[0.9792106586224232],"accuracy":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"f1_score_macro":[0.9739603709731586],"recall_score_macro":[0.9747222222222222],"average_precision_score_micro":[0.9986928104575163],"f1_score_micro":[0.9764705882352942]},"8225b235-bbc9-4c45-907f-aadd86c28980_17":{"recall_score_macro":[0.9747222222222222],"average_precision_score_micro":[0.9967851686598271],"log_loss":[0.07453153105467879],"accuracy":[0.9764705882352942],"f1_score_micro":[0.9764705882352942],"precision_score_weighted":[0.9792106586224232],"precision_score_micro":[0.9764705882352942],"recall_score_weighted":[0.9764705882352942],"weighted_accuracy":[0.9775270352989185],"f1_score_weighted":[0.9764009403497894],"AUC_macro":[0.9983333333333334],"average_precision_score_macro":[0.9980128205128205],"AUC_micro":[0.9965397923875431],"AUC_weighted":[0.9983333333333334],"norm_macro_recall":[0.9494444444444443],"balanced_accuracy":[0.9747222222222222],"f1_score_macro":[0.9739603709731586],"recall_score_micro":[0.9764705882352942],"matthews_correlation":[0.9511123000100223],"average_precision_score_weighted":[0.9985671191553545],"precision_score_macro":[0.9767094017094017]}}